---
title: "Regression on speed dating data"
author: "Jos√© Benardi de Souza Nunes"
date: 28/07/2018
output:
  html_notebook:
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

```{r setup, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(modelr)
library(GGally)
library(caret)
library(broom)
library(here)

theme_set(theme_bw())
```

# Data Overview

```{r}
data <- read_csv(here("data/speed-dating.csv"),
                 progress = FALSE,
                 col_types =cols(.default = col_integer(),
                                 int_corr = col_double(),
                                 field = col_character(),
                                 from = col_character(),
                                 career = col_character(),
                                 attr = col_double(),
                                 samerace = col_character(),
                                 sinc = col_double(),
                                 intel = col_double(),
                                 fun = col_double(),
                                 amb = col_double(),
                                 shar = col_double(),
                                 like = col_double(),
                                 prob = col_double(),
                                 match_es = col_double(),
                                 attr3_s = col_double(),
                                 sinc3_s = col_double(),
                                 intel3_s = col_double(),
                                 fun3_s = col_double(),
                                 amb3_s = col_double())) %>%
  mutate(from = as.numeric(factor(from)),
         gender = as.numeric(factor(gender)),
         samerace = as.numeric(factor(samerace)))

data %>%
  glimpse()
```

```{r}
data %>%
  na.omit(race) %>%
  ggplot(aes(race, ..prop..)) +
  geom_bar()
```

* Most of the participants are white (code = 2)
* There were no native americans involved (code = 5) 

## Choosing promising candidate variables

```{r}
require(GGally)

data %>% 
  select(like,fun,amb,attr,
         sinc,intel,shar,prob,
         fun3_s,amb3_s,attr3_s,
         sinc3_s,intel3_s,samerace,
         gender,from) %>% 
  na.omit() %>%
  ggcorr(palette = "RdBu", label = TRUE,
       hjust = 0.75, label_size = 3, nbreaks = 5) +
  ggtitle("Correlation plot for employed variables")
```

* What a person (p1) believes about herself/himself doesn't show promising results in terms of correlation
* Among what p1 thinks about p2 how *ambitious* p1 thinks p2 is shows the weakest correlation with how much p1 likes p2.
* Intelligence has interesting interactions with sincerity and ambition.

<br>

```{r}
data %>% 
  select(like,fun,attr,sinc,
         intel,shar,prob) %>% 
  na.omit() %>%
  ggpairs(upper = list(continuous = "density"), 
        lower = list(continuous = wrap("cor", size=5)),
        axisLabels = 'show',progress = F) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Regarding the relatinship with the response variable "**like**":

* Looking at the bidimensional density plot**fun** and **attr** have a cleaner and clearer connection with **like** as expected from what we saw in terms of correlation.
* Despite unpromising results in correlation **prob** has a somewhat clean interaction with **like** in terms of bidimensional density plot. Might be worth looking into.

<br>

```{r}
data %>%
  na.omit(fun, like) %>%
  ggplot(aes(fun, like)) +
  stat_density2d(aes(fill = ..level..),
                 geom = "polygon")
```

* Intuition would suggest a positive interaction between being seen as fun and being liked, that interaction being of considerable magnitude.

```{r}
data %>%
  na.omit(attr, like) %>%
  ggplot(aes(attr, like)) +
  stat_density2d(aes(fill = ..level..),
                 geom = "polygon")
```

* Intuition would suggest a positive interaction between being seen as attractive and being liked (no surprise there), that interaction being of considerable magnitude.

## Split Data for Cross Validation

```{r}
data %>%  # Keep only candidate and response variables
  select(fun, prob, order,
         attr, sinc, prob, shar, 
         intel, like, gender, samerace) %>%
  na.omit() -> data  # remove NAs

data %>% ## Put numeric predictor variables on same scale 
   mutate_at(.vars = vars(fun, prob, order,attr,
                          sinc, prob, shar,intel),
             .funs = funs(as.numeric(scale(.)))) -> data_scaled

data_scaled %>%
  glimpse()
```

<br>

#### For the sake of simplicity we'll follow the (80/20) thumb rule (based on Pareto's principle) and put 80% of our dataset in the training set and 20% in the test set. 

<br>

```{r}
set.seed(101) # We set the set for reason of reproducibility

## Adding surrogate key to dataframe
data_scaled$id <- 1:nrow(data_scaled)

data_scaled %>% 
  dplyr::sample_frac(.8) -> training

training %>% 
  glimpse()
```

```{r}
dplyr::anti_join(data_scaled, 
                 training, 
                 by = 'id') -> testing
testing %>% 
  glimpse()
```


# Applying Regression Models

## Intelligence related Model

```{r}
mod <- lm(like ~ fun + attr + shar + sinc + prob + sinc * intel + intel, 
          data = training)

glance(mod) 
``` 

```{r}
tidy(mod, 
     conf.int = TRUE, 
     conf.level = 0.95)
```

```{r}
tidy(mod, 
     conf.int = TRUE, 
     conf.level = 0.95)  %>%
  filter(term != "(Intercept)") %>%
  ggplot(aes(term, estimate, ymin = conf.low, ymax = conf.high)) +
  geom_errorbar(size = 0.8, width= 0.4) +
  geom_point(color = "red", size = 2) +
  geom_hline(yintercept = 0, colour = "darkred")
```

### Residual Analysis

Let's keep the residue data in a specific dataframe

```{r}
mod.res <- resid(mod)
std.resid <- rstandard(mod)
like <- training$like

resid_data <- data.frame(mod.res,std.resid,like,
                       stringsAsFactors=FALSE)
resid_data %>% 
  sample_n(10)
```


```{r}
resid_data %>%
  ggplot(aes(like, mod.res)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0,
             color = "red") +
  labs(x = "Response Variable (like)", y = "Residue") +
  ggtitle("Residual Plot")
```

```{r}
mod %>%
  ggplot(aes(.fitted, .resid)) + 
  geom_point() +
  stat_smooth(method="loess") + 
  geom_hline(yintercept=0, col="red", linetype="dashed") + 
  xlab("Fitted values") + ylab("Residuals") + 
  ggtitle("Residual vs Fitted Plot")
```


```{r}
y <- quantile(resid_data$std.resid[!is.na(resid_data$std.resid)], c(0.25, 0.75))
x <- qnorm(c(0.25, 0.75))
slope <- diff(y)/diff(x)
int <- y[1L] - slope * x[1L]

resid_data %>%
  ggplot(aes(sample=std.resid)) +
  stat_qq(shape=1, size=3) +      # open circles
  labs(title="Normal Q-Q",        # plot title
  x="Theoretical Quantiles",      # x-axis label
  y="Standardized Residuals") +   # y-axis label
  geom_abline(slope = slope,
              color = "red",
              size = 0.8,
              intercept = int,
              linetype="dashed")  # dashed reference line
```

```{r}
mod %>%
  ggplot(aes(.fitted, 
             sqrt(abs(.stdresid)))) + 
  geom_point(na.rm=TRUE) + 
  stat_smooth(method="loess",
              na.rm = TRUE) +
  labs(title = "Scale-Location",
       x= "Fitted Value",
       y = expression(sqrt("|Standardized residuals|")))
```

```{r}
mod %>%
  ggplot(aes(.hat, .stdresid)) + 
  geom_point(aes(size=.cooksd), na.rm=TRUE) +
  stat_smooth(method="loess", na.rm=TRUE) +
  xlab("Leverage")+ylab("Standardized Residuals") + 
  ggtitle("Residual vs Leverage Plot") + 
  scale_size_continuous("Cook's Distance", range=c(1,5)) +    
  theme(legend.position="bottom")
```

```{r}
mod %>%
  ggplot(aes(.hat, .cooksd)) + 
  geom_point(na.rm=TRUE) + 
  stat_smooth(method="loess", na.rm=TRUE) + 
  xlab("Leverage hii")+ylab("Cook's Distance") + 
  ggtitle("Cook's dist vs Leverage hii/(1-hii)") + 
  geom_abline(slope=seq(0,3,0.5), color="gray", linetype="dashed")
```

### Cross Validation

#### Validation Set Approach

```{r}
predictions <- mod %>% predict(testing)

data.frame( R2 = caret::R2(predictions, testing$like),
            RMSE = caret::RMSE(predictions, testing$like),
            MAE = caret::MAE(predictions, testing$like),
            ERR = caret::RMSE(predictions, testing$like)/
              mean(testing$like))
```

## Gender related Model

```{r}
mod <- lm(like ~ fun + attr + gender + shar * gender + sinc + prob, 
          data = training)

glance(mod) 
``` 

```{r}
tidy(mod, 
     conf.int = TRUE, 
     conf.level = 0.95)
```

```{r}
tidy(mod, 
     conf.int = TRUE, 
     conf.level = 0.95)  %>%
  filter(term != "(Intercept)") %>%
  ggplot(aes(term, estimate, ymin = conf.low, ymax = conf.high)) +
  geom_errorbar(size = 0.8, width= 0.4) +
  geom_point(color = "red", size = 2) +
  geom_hline(yintercept = 0, colour = "darkred")
```

### Residual Analysis

Let's keep the residue data in a specific dataframe

```{r}
mod.res <- resid(mod)
std.resid <- rstandard(mod)
like <- training$like

resid_data <- data.frame(mod.res,std.resid,like,
                       stringsAsFactors=FALSE)
resid_data %>% 
  sample_n(10)
```


```{r}
resid_data %>%
  ggplot(aes(like, mod.res)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0,
             color = "red") +
  labs(x = "Response Variable (like)", y = "Residue") +
  ggtitle("Residual Plot")
```

```{r}
mod %>%
  ggplot(aes(.fitted, .resid)) + 
  geom_point() +
  stat_smooth(method="loess") + 
  geom_hline(yintercept=0, col="red", linetype="dashed") + 
  xlab("Fitted values") + ylab("Residuals") + 
  ggtitle("Residual vs Fitted Plot")
```


```{r}
y <- quantile(resid_data$std.resid[!is.na(resid_data$std.resid)], c(0.25, 0.75))
x <- qnorm(c(0.25, 0.75))
slope <- diff(y)/diff(x)
int <- y[1L] - slope * x[1L]

resid_data %>%
  ggplot(aes(sample=std.resid)) +
  stat_qq(shape=1, size=3) +      # open circles
  labs(title="Normal Q-Q",        # plot title
  x="Theoretical Quantiles",      # x-axis label
  y="Standardized Residuals") +   # y-axis label
  geom_abline(slope = slope,
              color = "red",
              size = 0.8,
              intercept = int,
              linetype="dashed")  # dashed reference line
```

```{r}
mod %>%
  ggplot(aes(.fitted, 
             sqrt(abs(.stdresid)))) + 
  geom_point(na.rm=TRUE) + 
  stat_smooth(method="loess",
              na.rm = TRUE) +
  labs(title = "Scale-Location",
       x= "Fitted Value",
       y = expression(sqrt("|Standardized residuals|")))
```

```{r}
mod %>%
  ggplot(aes(.hat, .stdresid)) + 
  geom_point(aes(size=.cooksd), na.rm=TRUE) +
  stat_smooth(method="loess", na.rm=TRUE) +
  xlab("Leverage")+ylab("Standardized Residuals") + 
  ggtitle("Residual vs Leverage Plot") + 
  scale_size_continuous("Cook's Distance", range=c(1,5)) +    
  theme(legend.position="bottom")
```

```{r}
mod %>%
  ggplot(aes(.hat, .cooksd)) + 
  geom_point(na.rm=TRUE) + 
  stat_smooth(method="loess", na.rm=TRUE) + 
  xlab("Leverage hii")+ylab("Cook's Distance") + 
  ggtitle("Cook's dist vs Leverage hii/(1-hii)") + 
  geom_abline(slope=seq(0,3,0.5), color="gray", linetype="dashed")
```

### Cross Validation

#### Validation Set Approach

```{r}
predictions <- mod %>% predict(testing)

data.frame( R2 = caret::R2(predictions, testing$like),
            RMSE = caret::RMSE(predictions, testing$like),
            MAE = caret::MAE(predictions, testing$like),
            ERR = caret::RMSE(predictions, testing$like)/
              mean(testing$like))
```


